{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossentropy method\n",
    "\n",
    "This notebook will teach you to solve reinforcement learning problems with crossentropy method. We'll follow-up by scaling everything up and using neural network policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb.\n",
      "env: DISPLAY=: 1\n"
     ]
    }
   ],
   "source": [
    "# In google collab, uncomment this:\n",
    "# !wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py\n",
    "\n",
    "# XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY = : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_states=500, n_actions=6\n"
     ]
    }
   ],
   "source": [
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"n_states=%i, n_actions=%i\" % (n_states, n_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create stochastic policy\n",
    "\n",
    "This time our policy should be a probability distribution.\n",
    "\n",
    "```policy[s,a] = P(take action a | in state s)```\n",
    "\n",
    "Since we still use integer state and action representations, you can use a 2-dimensional array to represent the policy.\n",
    "\n",
    "Please initialize policy __uniformly__, that is, probabililities of all actions should be equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = np.ones(shape=(n_states, n_actions)) / n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(policy) in (np.ndarray, np.matrix)\n",
    "assert np.allclose(policy, 1./n_actions)\n",
    "assert np.allclose(np.sum(policy, axis=1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play the game\n",
    "\n",
    "Just like before, but we also record all states and actions we took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(policy, t_max=10**4):\n",
    "    \"\"\"\n",
    "    Play game until end or for t_max ticks.\n",
    "    :param policy: an array of shape [n_states,n_actions] with action probabilities\n",
    "    :returns: list of states, list of actions and sum of rewards\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0.\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        a = np.random.choice(np.arange(n_actions), p=policy[s])\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # Record state, action and add up reward to states,actions and total_reward accordingly.\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, a, r = generate_session(policy)\n",
    "assert type(s) == type(a) == list\n",
    "assert len(s) == len(a)\n",
    "assert type(r) in [float, np.float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1e080d2828>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see the initial reward distribution\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sample_rewards = [generate_session(policy, t_max=1000)[-1] for _ in range(200)]\n",
    "\n",
    "plt.hist(sample_rewards, bins=20)\n",
    "plt.vlines([np.percentile(sample_rewards, 50)], [0], [\n",
    "           100], label=\"50'th percentile\", color='green')\n",
    "plt.vlines([np.percentile(sample_rewards, 90)], [0], [\n",
    "           100], label=\"90'th percentile\", color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossentropy method steps (2pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you're confused, see examples below. Please don't assume that states are integers (they'll get different later).\n",
    "    \"\"\"\n",
    "\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    \n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "    for i, ind in enumerate(rewards_batch >= reward_threshold):\n",
    "        if ind:\n",
    "            elite_states.extend(states_batch[i])\n",
    "            elite_actions.extend(actions_batch[i])\n",
    "\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "states_batch = [\n",
    "    [1, 2, 3],  # game1\n",
    "    [4, 2, 0, 2],  # game2\n",
    "    [3, 1]  # game3\n",
    "]\n",
    "\n",
    "actions_batch = [\n",
    "    [0, 2, 4],  # game1\n",
    "    [3, 2, 0, 1],  # game2\n",
    "    [3, 3]  # game3\n",
    "]\n",
    "rewards_batch = [\n",
    "    3,  # game1\n",
    "    4,  # game2\n",
    "    5,  # game3\n",
    "]\n",
    "\n",
    "test_result_0 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=0)\n",
    "test_result_40 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=30)\n",
    "test_result_90 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=90)\n",
    "test_result_100 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=100)\n",
    "\n",
    "assert np.all(test_result_0[0] == [1, 2, 3, 4, 2, 0, 2, 3, 1])  \\\n",
    "    and np.all(test_result_0[1] == [0, 2, 4, 3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 0 you should return all states and actions in chronological order\"\n",
    "assert np.all(test_result_40[0] == [4, 2, 0, 2, 3, 1]) and \\\n",
    "    np.all(test_result_40[1] == [3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 30 you should only select states/actions from two first\"\n",
    "assert np.all(test_result_90[0] == [3, 1]) and \\\n",
    "    np.all(test_result_90[1] == [3, 3]),\\\n",
    "    \"For percentile 90 you should only select states/actions from one game\"\n",
    "assert np.all(test_result_100[0] == [3, 1]) and\\\n",
    "    np.all(test_result_100[1] == [3, 3]),\\\n",
    "    \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(elite_states, elite_actions):\n",
    "    \"\"\"\n",
    "    Given old policy and a list of elite states/actions from select_elites,\n",
    "    return new updated policy where each action probability is proportional to\n",
    "\n",
    "    policy[s_i,a_i] ~ #[occurences of si and ai in elite states/actions]\n",
    "\n",
    "    Don't forget to normalize policy to get valid probabilities and handle 0/0 case.\n",
    "    In case you never visited a state, set probabilities for all actions to 1./n_actions\n",
    "\n",
    "    :param elite_states: 1D list of states from elite sessions\n",
    "    :param elite_actions: 1D list of actions from elite sessions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    new_policy = np.zeros([n_states, n_actions])\n",
    "    \n",
    "    for s, a in zip(elite_states, elite_actions):\n",
    "        new_policy[s, a] += 1\n",
    "    for i in range(new_policy.shape[0]):\n",
    "        s = new_policy[i].sum()\n",
    "        if s:\n",
    "            new_policy[i] /= s\n",
    "        else:\n",
    "            new_policy[i] = np.ones(n_actions) / n_actions\n",
    "\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "elite_states, elite_actions = ([1, 2, 3, 4, 2, 0, 2, 3, 1], [\n",
    "                               0, 2, 4, 3, 2, 0, 1, 3, 3])\n",
    "\n",
    "\n",
    "new_policy = update_policy(elite_states, elite_actions)\n",
    "\n",
    "assert np.isfinite(new_policy).all(\n",
    "), \"Your new policy contains NaNs or +-inf. Make sure you don't divide by zero.\"\n",
    "assert np.all(\n",
    "    new_policy >= 0), \"Your new policy can't have negative action probabilities\"\n",
    "assert np.allclose(new_policy.sum(\n",
    "    axis=-1), 1), \"Your new policy should be a valid probability distribution over actions\"\n",
    "reference_answer = np.array([\n",
    "    [1.,  0.,  0.,  0.,  0.],\n",
    "    [0.5,  0.,  0.,  0.5,  0.],\n",
    "    [0.,  0.33333333,  0.66666667,  0.,  0.],\n",
    "    [0.,  0.,  0.,  0.5,  0.5]])\n",
    "assert np.allclose(new_policy[:4, :5], reference_answer)\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def show_progress(rewards_batch, log, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset policy just in case\n",
    "policy = np.ones([n_states, n_actions])/n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = -62.588, threshold=7.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-009ee9b86707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# display results on chart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-89-b9dc7d468bd7>\u001b[0m in \u001b[0;36mshow_progress\u001b[0;34m(rewards_batch, log, reward_range)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/george/.local/lib/python3.6/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2053\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2054\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2270\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4395\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbox_artists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4396\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4397\u001b[0m             if (bbox is not None and\n\u001b[1;32m   4398\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1932\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         \u001b[0;31m# that have been set by `fig.align_xlabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1934\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1919\u001b[0;31m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1920\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m             \u001b[0mbboxes2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1On\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m                 \u001b[0mextent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m                 \u001b[0mticklabelBoxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2On\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mrotated\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mnecessary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prop_tup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_prop_tup\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    873\u001b[0m         return (x, y, self.get_text(), self._color,\n\u001b[1;32m    874\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verticalalignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_horizontalalignment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m                 \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rotation_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         l = (tuple(self.get_family()),\n\u001b[0m\u001b[1;32m    623\u001b[0m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 250  # sample this many sessions\n",
    "percentile = 50  # take this percent of session with highest rewards\n",
    "learning_rate = 0.5  # add this thing to all counts for stability\n",
    "\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    sessions = [generate_session(policy) for _ in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = zip(*sessions)\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "\n",
    "    new_policy = update_policy(elite_states, elite_actions)\n",
    "\n",
    "    policy = learning_rate*new_policy + (1-learning_rate)*policy\n",
    "\n",
    "    # display results on chart\n",
    "    show_progress(rewards_batch, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digging deeper: approximate crossentropy with neural nets\n",
    "\n",
    "![img](https://casd35.wikispaces.com/file/view/digging_deeper_final.jpg/359658499/503x260/digging_deeper_final.jpg)\n",
    "\n",
    "In this section we will train a neural network policy for continuous state space game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "module 'gym.envs.box2d' has no attribute 'LunarLander'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2418\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gym.envs.box2d' has no attribute 'LunarLander'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-af004225e201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if you see \"<classname> has no attribute .env\", remove .env or update gym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# env = gym.make(\"CartPole-v0\").env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LunarLander-v2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, id, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Making new env: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# We used to have people override _reset/_step rather than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# reset/step. Set _gym_disable_underscore_compat = True on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpkg_resources\u001b[0m \u001b[0;31m# takes ~400ms to load, so we import it lazily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mentry_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEntryPoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry_point\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: module 'gym.envs.box2d' has no attribute 'LunarLander'"
     ]
    }
   ],
   "source": [
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "# env = gym.make(\"CartPole-v0\").env\n",
    "env = gym.make(\"LunarLander-v2\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=True)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create agent\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "agent = MLPClassifier(hidden_layer_sizes=(20, 20),\n",
    "                      activation='relu',\n",
    "                      alpha=0.001,\n",
    "                      warm_start=True,  # keep progress between .fit(...) calls\n",
    "                      max_iter=1  # make only 1 iteration on each .fit(...)\n",
    "                      )\n",
    "# initialize agent to the dimension of state an amount of actions\n",
    "agent.fit([env.reset()]*n_actions, range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(t_max=1000):\n",
    "\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        # predict array of action probabilities\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "\n",
    "        a = np.random.choice(np.arange(n_actions), p=probs)\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "        if a != 1:\n",
    "            r /= 3\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = -67.285, threshold=-67.333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "warm_start can only be used where `y` has the same classes as in the previous call to fit. Previously got [0 1 2], `y` has [0 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-4485236dce48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0melite_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melite_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_elites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melite_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melite_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \"\"\"\n\u001b[1;32m    976\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 977\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    322\u001b[0m                              hidden_layer_sizes)\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    926\u001b[0m                                  \u001b[0;34m\"the same classes as in the previous \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                                  \u001b[0;34m\"call to fit. Previously got %s, `y` has %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                                  (self.classes_, classes))\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: warm_start can only be used where `y` has the same classes as in the previous call to fit. Previously got [0 1 2], `y` has [0 2]"
     ]
    }
   ],
   "source": [
    "n_sessions = 500\n",
    "percentile = 45\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [generate_session(500) for _ in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "    \n",
    "    agent.fit(elite_states, elite_actions)\n",
    "\n",
    "    show_progress(rewards_batch, log, reward_range=[-1000, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40706553, 0.00160296, 0.59133151],\n",
       "       [0.4069504 , 0.00159645, 0.59145315],\n",
       "       [0.40676316, 0.00158645, 0.5916504 ],\n",
       "       ...,\n",
       "       [0.39939406, 0.00122043, 0.59938551],\n",
       "       [0.40007227, 0.00125563, 0.59867211],\n",
       "       [0.40062158, 0.00128652, 0.5980919 ]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.predict_proba(elite_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(gym.make(\"MountainCar-v0\"),\n",
    "                           directory=\"videos\", force=True)\n",
    "sessions = [generate_session(2500) for _ in range(100)]\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./videos/openaigym.video.4.17394.video000001.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(\n",
    "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-1]))  # this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pts) Find out how the algorithm performance changes if you change different percentile and different n_sessions.\n",
    "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here.  Preferably with plot/report to support it.>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (bonus: 4++ pt) Devise a way to speed up training at least 2x against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  * __Please list what you did in anytask submission form__\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [mountaincar](https://gym.openai.com/envs/MountainCar-v0), [lunarlander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Start with [\"Pendulum-v0\"](https://github.com/openai/gym/wiki/Pendulum-v0).\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
